{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "D:/Specim/Lab_Calibrations/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import spectral as sp\n",
    "from spectral import envi\n",
    "import configparser\n",
    "import pandas as pd\n",
    "\n",
    "# To access the custom modules of the hyperspectral_toolchain, give the path to the src folder \"...hyperspectral_toolchain/src/\"\n",
    "module_path = 'C:/Users/haavasl/VSCodeProjects/hyperspectral_toolchain/src/'\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from lib.specim_parsing_utils import Specim\n",
    "from scripts.modulate_config import prepend_data_dir_to_relative_paths\n",
    "\n",
    "MISSION_NAME_PREFIX = '2022-08-31-060000-Remoy-Specim' # I use UTC time to avoid any timezone BS\n",
    "\n",
    "DATE = '2022-08-31'\n",
    "MISSION_DIR = 'D:/Specim/Missions/2022-08-31-Remøy/2022-08-31_0800_HSI/'\n",
    "CAL_DIR = 'D:/Specim/Lab_Calibrations/'\n",
    "OUT_DIR = 'D:/HyperspectralDataAll/HI/' + MISSION_NAME_PREFIX + '/'\n",
    "\n",
    "ACTIVE_SENSOR_SPATIAL_PIXELS = 1024 # Constant for AFX10\n",
    "ACTIVE_SENSOR_SPECTRAL_PIXELS = 448 # Constant for AFX10\n",
    "\n",
    "print(CAL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a configuration object for the processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# TODO: The config_file should be better explained, and generated based on user settings. Dictionary could be good alternative\n",
    "config_file_path = OUT_DIR + 'configuration.ini'\n",
    "\n",
    "# Set the data directory for the mission (locally where the data is stored)\n",
    "prepend_data_dir_to_relative_paths(config_path=config_file_path, DATA_DIR = OUT_DIR)\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(config_file_path)\n",
    "\n",
    "\n",
    "specim_object = Specim(mission_path=MISSION_DIR, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nA mission directory is organized as follows. Missions need to be \\n├───MissionDir\\n│   ├───configuration.ini # Configurations goes here\\n│   ├───<the_name_of_mat_file>.mat # Navigation data goes here\\n│   ├───Input # Necessary input for georeferencing\\n│   │   ├───H5 #The *.h5 files go here\\n│   │   ├───Calib #The camera calibration\\n│   │   └───GIS # The 3D terrain model and more goes here (not used here)\\n│   ├───Output\\n│   │   ├───3DModels # Here we get a point cloud version of the data (if we want)\\n│   │   └───GIS\\n│   │       ├───FootPrints\\n│   │       ├───HSIDatacubes\\n│   │       └───RGBComposites\\n│   ├───Intermediate\\n│   │   ├───Pickle (not relevant)\\n│   │   └───OrthoReshaped (not relevant)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "A mission directory is organized as follows. Missions need to be \n",
    "├───MissionDir\n",
    "│   ├───configuration.ini # Configurations goes here\n",
    "│   ├───<the_name_of_mat_file>.mat # Navigation data goes here\n",
    "│   ├───Input # Necessary input for georeferencing\n",
    "│   │   ├───H5 #The *.h5 files go here\n",
    "│   │   ├───Calib #The camera calibration\n",
    "│   │   └───GIS # The 3D terrain model and more goes here (not used here)\n",
    "│   ├───Output\n",
    "│   │   ├───3DModels # Here we get a point cloud version of the data (if we want)\n",
    "│   │   └───GIS\n",
    "│   │       ├───FootPrints\n",
    "│   │       ├───HSIDatacubes\n",
    "│   │       └───RGBComposites\n",
    "│   ├───Intermediate\n",
    "│   │   ├───Pickle (not relevant)\n",
    "│   │   └───OrthoReshaped (not relevant)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haavasl\\AppData\\Local\\miniconda3\\envs\\specim\\lib\\site-packages\\spectral\\io\\envi.py:175: UserWarning: Parameters with non-lowercase names encountered and converted to lowercase. To retain source file parameter name capitalization, set spectral.settings.envi_support_nonlowercase_params to True.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Reading envi format is achieved with spectral python.\n",
    "# This cell reads the main capture and finds relevant configs from *.hdr data\n",
    "\n",
    "\n",
    "\n",
    "PATTERN_ENVI = '*.hdr'\n",
    "CAPTURE_DIR = MISSION_DIR + '/capture/'\n",
    "\n",
    "search_path_envi = os.path.normpath(os.path.join(CAPTURE_DIR, PATTERN_ENVI))\n",
    "ENVI_HDR_FILE_PATH = glob.glob(search_path_envi)[0]\n",
    "\n",
    "spectral_image_obj = envi.open(ENVI_HDR_FILE_PATH)\n",
    "\n",
    "# Read all meta of interest (make explicit to developer and accessible with autocomplete)\n",
    "class Metadata:\n",
    "    pass\n",
    "\n",
    "metadata_obj = Metadata()\n",
    "metadata_obj.autodarkstartline = int(spectral_image_obj.metadata['autodarkstartline'])\n",
    "metadata_obj.n_lines = int(spectral_image_obj.metadata['lines'])\n",
    "metadata_obj.n_bands = int(spectral_image_obj.metadata['bands'])\n",
    "metadata_obj.n_pix = int(spectral_image_obj.metadata['samples'])\n",
    "metadata_obj.t_exp_ms = float(spectral_image_obj.metadata['tint'])\n",
    "metadata_obj.fps = float(spectral_image_obj.metadata['fps'])\n",
    "metadata_obj.description = spectral_image_obj.metadata['description']\n",
    "metadata_obj.file_type = spectral_image_obj.metadata['file type']\n",
    "metadata_obj.sensor_type = spectral_image_obj.metadata['sensor type']\n",
    "metadata_obj.acquisition_date = spectral_image_obj.metadata['acquisition date']\n",
    "metadata_obj.sensorid = spectral_image_obj.metadata['sensorid']\n",
    "metadata_obj.interleave = spectral_image_obj.metadata['interleave']\n",
    "metadata_obj.data_type = spectral_image_obj.metadata['data type']\n",
    "# USE FILES FROM LAB, not HEADER metadata_obj.wavelengths = np.array(spectral_image_obj.bands.centers)\n",
    "#NOT CORRECT!!!!!! This is spectral sampling distance: metadata_obj.fwhm = np.array(spectral_image_obj.bands.bandwidths)\n",
    "metadata_obj.binning_spatial = int(ACTIVE_SENSOR_SPATIAL_PIXELS/metadata_obj.n_pix)\n",
    "metadata_obj.binning_spectral = int(ACTIVE_SENSOR_SPECTRAL_PIXELS/metadata_obj.n_bands)\n",
    "\n",
    "# Binning solely determines which calibration files be used.\n",
    "\n",
    "# It holds a csv like format\n",
    "\n",
    "\n",
    "\n",
    "specim_object.metadata_obj = metadata_obj # Allow accesability for Specim Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the binning info, we can locate relevant calibration files, including 1) spectral, 2) geometric, 3) radiometric, and dark frame (from capture).\n",
    "\n",
    "We start with the spectral calibration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Reads spectral calibration based on binning into a wavelength array and a fwhm array\"\"\"\n",
    "\n",
    "# Comprehensive band info (center, fwhm) is found in \"CAL_DIR/wlcal<spectral binning>b_fwhm.wls\"\n",
    "PATTERN_BAND_INFO = '*'+ str(metadata_obj.binning_spectral) + 'b_fwhm.wls'\n",
    "# Linux-CLI search for file.\n",
    "search_path_bands = os.path.normpath(os.path.join(CAL_DIR, PATTERN_BAND_INFO))\n",
    "BAND_FILE_PATH = glob.glob(search_path_bands)[0]\n",
    "\n",
    "df_bands = pd.read_csv(BAND_FILE_PATH, header=None, sep = '\\s+')\n",
    "df_bands.columns = ['Wavelength_nm', 'FWHM_nm']\n",
    "\n",
    "specim_object.wavelengths = np.array(df_bands['Wavelength_nm'])\n",
    "specim_object.fwhm = np.array(df_bands['FWHM_nm'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will here go through the loading of Specim geometric camera model. The first step is to load the angular Field-of-View file (AFOV) from the manufacturer. Then boresight angles and lever arms can be set, if relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel-directions is found in \"CAL_DIR/FOV_****_<spatial binning>b.txt\" \n",
    "\n",
    "PATTERN_FOV = 'FOV*' + '_' +  str(metadata_obj.binning_spatial) + 'b.txt'\n",
    "\n",
    "# Search for fov file.\n",
    "search_path_fov = os.path.normpath(os.path.join(CAL_DIR, PATTERN_FOV))\n",
    "FOV_FILE_PATH = glob.glob(search_path_fov)[0]\n",
    "\n",
    "# Calculates a camera model based on FOV file \n",
    "specim_object.read_fov_file(fov_file_path=FOV_FILE_PATH)\n",
    "\n",
    "df_fov = pd.read_csv(FOV_FILE_PATH, header=None, sep = ',')\n",
    "\n",
    "df_fov.columns = ['Pixel_Nr', 'View_Angle_Deg', 'Unknown']\n",
    "\n",
    "specim_object.view_angles = np.array(df_fov['View_Angle_Deg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rx': 0, 'ry': 0, 'rz': 0, 'tx': 0, 'ty': 0, 'tz': 0, 'f': 754.9669306613682, 'cx': 255.0099175768686, 'k1': -72.31616804110381, 'k2': -389.5781973543412, 'k3': 4.075384334827561, 'width': 512}\n"
     ]
    }
   ],
   "source": [
    "binning_spatial = metadata_obj.binning_spatial\n",
    "param_dict = Specim.fov_2_param(fov = specim_object.view_angles)\n",
    "print(param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The addition of boresight angles can be done by editing tx, ty, tz, and rx, ry, rz in the \"OUTDIR/Input/Calib\". \n",
    "\n",
    "[tx, ty, tz] is the vector from HSI focal centre to reference origin (e.g. IMU) given in the reference frame. So if your BODY frame defines forward, right, down on the vehicle:\n",
    "\n",
    "[tx, ty, tz] = [1, 1, 1] means that HSI is 1 m behind, 1 m left of and 1 m above the IMU.\n",
    "\n",
    "Secondly, [rx, ry, rz] are Euler angles in radians with order 'ZYX'. If using another rotation convention, it's recommended to convert with scipy.spatial.Rotation. Example:\n",
    "\n",
    "    import scipy.spatial.Rotation as RotLib\n",
    "\n",
    "    # Let's say you have a rotation matrix transforming a vector from HSI frame to IMU frame\n",
    "    R_hsi_rgb = [[0, -1, 0],\n",
    "                 [1, 0, 0],\n",
    "                 [0, 0, 1]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.geometry import CalibHSI\n",
    "# Before writing the calibration file, we need to think about the relative configuration of the Specim imager. \n",
    "# X: For simplicity let's assume that the x- axis of the HSI is pointing in opposite (-) direction as body y-axis, namely starboard\n",
    "# Y: For simplicity let's assume that the y- axis of the HSI is pointing in same (+) direction as body x-axis, namely backward\n",
    "# Z: For simplicity let's assume that the z- axis of the HSI is pointing in same direction as body z-axis (+), namely downwards\n",
    "from scipy.spatial.transform import Rotation as RotLib\n",
    "\n",
    "x_hsi = np.array([0, -1, 0]).reshape((-1,1)) # Same as statement above\n",
    "y_hsi = np.array([1, 0, 0]).reshape((-1,1)) # Same as statement above\n",
    "z_hsi = np.array([0, 0, 1]).reshape((-1,1)) # Same as statement above\n",
    "\n",
    "# This knowledge allows us to assemble the rotation matrix for rotating points from HSI frame to RGB frame\n",
    "R_hsi_rgb = np.concatenate((x_hsi, y_hsi, z_hsi), axis = 1)\n",
    "r_zyx = RotLib.from_matrix(R_hsi_rgb).as_euler('ZYX', degrees=False)\n",
    "\n",
    "# Lever arms are per my knowledge unknown at time (defaults to 0) being but they should be set if known\n",
    "# param_dict['tz'] = 1 means that HSI origin is 1 m above body origin\n",
    "# param_dict['ty'] = 1 means that HSI origin is 1 m to the left of body origin\n",
    "# param_dict['tz'] = 1 means that HSI origin is 1 m behind of body origin\n",
    "\n",
    "param_dict['rz'] = r_zyx[0]\n",
    "param_dict['ry'] = r_zyx[1]\n",
    "param_dict['rx'] = r_zyx[2]\n",
    "\n",
    "param_dict['tz'] = 0\n",
    "param_dict['ty'] = 0\n",
    "param_dict['tz'] = 0\n",
    "\n",
    "CAMERA_CALIB_XML_DIR = OUT_DIR + 'Input/Calib/'\n",
    "\n",
    "file_name_xml = 'HSI_' + str(binning_spatial) + 'b.xml'\n",
    "xml_cal_write_path = CAMERA_CALIB_XML_DIR + file_name_xml\n",
    "\n",
    "CalibHSI(file_name_cal_xml= xml_cal_write_path, \n",
    "                 config = config, \n",
    "                 mode = 'w', \n",
    "                 param_dict = param_dict)\n",
    "\n",
    "\n",
    "# Set value in config file:\n",
    "config.set('Relative Paths', 'hsicalibfile', value = 'Input/Calib/' + file_name_xml)\n",
    "\n",
    "with open(config_file_path, 'w') as configfile:\n",
    "        config.write(configfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Function added to remedy lacking byte-order entry in header files of radiometric calibration data\"\"\"\n",
    "def add_byte_order_to_envi_header(header_file_path, byte_order_value):\n",
    "    # Read the existing ENVI header\n",
    "    with open(header_file_path, 'r') as f:\n",
    "        header_lines = f.readlines()\n",
    "\n",
    "    # Look for the line where you want to add \"byte order\"\n",
    "    for i, line in enumerate(header_lines):\n",
    "        if line.startswith('byte order'):\n",
    "            # If it already exists, update the value\n",
    "            header_lines[i] = f'byte order = {byte_order_value}\\n'\n",
    "            break\n",
    "    else:\n",
    "        # If it doesn't exist, add it to the end of the header\n",
    "        header_lines.append(f'byte order = {byte_order_value}\\n')\n",
    "\n",
    "    # Save the updated header\n",
    "    with open(header_file_path, 'w') as f:\n",
    "        f.writelines(header_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to read in radiometric frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Extract radiometric frame from dedicated file\"\"\"\n",
    "\n",
    "PATTERN_ENVI_CAL = '*_' +str(metadata_obj.binning_spectral) + 'x' +  str(metadata_obj.binning_spatial) + '.hdr'\n",
    "\n",
    "search_path_envi_cal = os.path.normpath(os.path.join(CAL_DIR, PATTERN_ENVI_CAL))\n",
    "ENVI_CAL_HDR_FILE_PATH = glob.glob(search_path_envi_cal)[0]\n",
    "\n",
    "RAD_CAL_BYTE_ORDER = 0\n",
    "\n",
    "add_byte_order_to_envi_header(header_file_path=ENVI_CAL_HDR_FILE_PATH, byte_order_value=RAD_CAL_BYTE_ORDER)\n",
    "\n",
    "ENVI_CAL_IMAGE_FILE_PATH = ENVI_CAL_HDR_FILE_PATH.split('.')[0] + '.cal' # SPECTRAL does not expect this suffix by default\n",
    "\n",
    "# For some reason, the byte order\n",
    "\n",
    "radiometric_image_obj = envi.open(ENVI_CAL_HDR_FILE_PATH, image = ENVI_CAL_IMAGE_FILE_PATH)\n",
    "\n",
    "cal_n_lines = int(radiometric_image_obj.metadata['lines'])\n",
    "cal_n_bands = int(radiometric_image_obj.metadata['bands'])\n",
    "cal_n_pix = int(radiometric_image_obj.metadata['samples'])\n",
    "\n",
    "radiometric_frame = radiometric_image_obj[:,:,:].reshape((cal_n_pix, cal_n_bands))\n",
    "\n",
    "specim_object.radiometric_frame = radiometric_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to load the darkframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"1) Crop the hyperspectral data according to the start-stop lines. 2) Write datacube to appropriate directory\"\"\"\n",
    "# To ensure that the plots actually do appear in this notebook:\n",
    "%matplotlib qt\n",
    "\n",
    "# Establish dark frame data (at end of recording)\n",
    "data_dark = spectral_image_obj[metadata_obj.autodarkstartline:metadata_obj.n_lines, :, :]\n",
    "dark_frame = np.median(data_dark, axis = 0)\n",
    "\n",
    "specim_object.dark_frame = dark_frame\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The navigation data is given as messages is a *.nav file. Locate the file and parse it into a suitable format. From NAVIGEOPRO we'd get a sync file giving the pose per scan. Matching against such a file makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the starting/stopping lines\n",
    "import pandas as pd\n",
    "\n",
    "PATTERN_START_STOP = '*.txt'\n",
    "START_STOP_DIR = MISSION_DIR + '/start_stop_lines'\n",
    "\n",
    "search_path_lines_start_stop = os.path.normpath(os.path.join(START_STOP_DIR, PATTERN_START_STOP))\n",
    "LINES_START_STOP_FILE_PATH = glob.glob(search_path_lines_start_stop)[0]\n",
    "\n",
    "header = 0\n",
    "\n",
    "df_start_stop = pd.read_csv(filepath_or_buffer=LINES_START_STOP_FILE_PATH, header=header, sep=' ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now read the *.nav file\n",
    "NAV_PATTERN = '*.nav'\n",
    "\n",
    "search_path_nav = os.path.normpath(os.path.join(CAPTURE_DIR, NAV_PATTERN))\n",
    "nav_file_path = glob.glob(search_path_nav)[0]\n",
    "\n",
    "# Parse the position/orientation messages\n",
    "specim_object.read_nav_file(nav_file_path=nav_file_path, date = DATE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the frame timestamps from sync data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1661925888.73\n"
     ]
    }
   ],
   "source": [
    "import pymap3d as pm\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "\n",
    "df_imu = pd.DataFrame(specim_object.imu_data)\n",
    "df_gnss = pd.DataFrame(specim_object.gnss_data)\n",
    "df_sync_hsi = pd.DataFrame(specim_object.sync_data)\n",
    "# Define the time stamps of HSI frames\n",
    "\n",
    "\n",
    "# Let's consider this an interpolation problem. Every new sync means a new fps # frames:\n",
    "sync_frames = df_sync_hsi['HsiFrameNum']\n",
    "sync_times = df_sync_hsi['TimestampAbs']\n",
    "hsi_frames = np.arange(metadata_obj.autodarkstartline)\n",
    "\n",
    "\n",
    "hsi_timestamps_total = interp1d(x = sync_frames, y= sync_times, fill_value = 'extrapolate')(x = hsi_frames)\n",
    "\n",
    "\n",
    "# Secondly, for ease, let us interpolate position data to imu time (avoids rotational interpolation)\n",
    "imu_time = df_imu['TimestampAbs']\n",
    "\n",
    "# Drop the specified regular clock time (as it is not needed)\n",
    "df_gnss = df_gnss.drop(columns=['TimestampClock'])\n",
    "\n",
    "# Interpolate each column in GNSS data based on 'imu_time'\n",
    "interpolated_values = {\n",
    "    column: np.interp(imu_time, df_gnss['TimestampAbs'], df_gnss[column])\n",
    "    for column in df_gnss.columns if column != 'TimestampAbs'\n",
    "}\n",
    "\n",
    "\n",
    "# Create a new DataFrame with the interpolated values\n",
    "df_gnss_interpolated = pd.DataFrame({'time': imu_time, **interpolated_values})\n",
    "\n",
    "# The position defined in geodetic coordinates\n",
    "lat = np.array(df_gnss_interpolated['Lat']).reshape((-1,1))\n",
    "lon = np.array(df_gnss_interpolated['Lon']).reshape((-1,1))\n",
    "ellipsoid_height = np.array(df_gnss_interpolated['AltMSL'] + df_gnss_interpolated['AltGeoid']).reshape((-1,1))\n",
    "\n",
    "# Assumes WGS-84 (default GNSS frame)\n",
    "x, y, z = pm.geodetic2ecef(lat = lat, lon = lon, alt = ellipsoid_height, deg=True)\n",
    "\n",
    "# Lastly, calculate the roll, pitch, yaw\n",
    "roll = np.array(df_imu['Roll']).reshape((-1,1))\n",
    "pitch = np.array(df_imu['Pitch']).reshape((-1,1))\n",
    "yaw = np.array(df_imu['Yaw']).reshape((-1,1))\n",
    "\n",
    "# Roll pitch yaw are stacked with in an unintuitive attribute. The euler angles with rotation order ZYX are Yaw Pitch Roll\n",
    "specim_object.eul_zyx = np.concatenate((roll, pitch, yaw), axis = 1)\n",
    "\n",
    "# Position is stored as ECEF cartesian coordinates (mutually orthogonal axis) instead of spherioid-like lon, lat, alt\n",
    "specim_object.position_ecef = np.concatenate((x,y,z), axis = 1)\n",
    "specim_object.nav_timestamp = imu_time\n",
    "specim_object.t_exp_ms = metadata_obj.t_exp_ms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last preprocessing step is writing to h5 files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the data for use in the geometric processing pipeline\n",
    "h5_dict_write = {'eul_zyx' : 'raw/nav/euler_angles',\n",
    "           'position_ecef' : 'raw/nav/position_ecef',\n",
    "           'nav_timestamp' : 'raw/nav/timestamp',\n",
    "           'radiance_cube': 'processed/radiance/radiance_cube',\n",
    "           't_exp_ms': 'processed/radiance/t_exp_ms',\n",
    "           'hsi_timestamps': 'processed/radiance/timestamp',\n",
    "           'view_angles': 'processed/radiance/calibration/geometric/view_angles',\n",
    "           'wavelengths' : 'processed/radiance/calibration/spectral/wavelengths',\n",
    "           'fwhm' : 'processed/radiance/calibration/spectral/fwhm',\n",
    "           'dark_frame' : 'processed/radiance/calibration/dark_frame',\n",
    "           'radiometric_frame' : 'processed/radiance/calibration/radiometric_frame'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to write all the data to a h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\"\"\"Writer for the h5 file format using a dictionary. The user provides h5 hierarchy paths as values and keys are the names given to the attributes of the specim object.\n",
    "A similar write process could be applied to metadata.\"\"\"\n",
    "def specim_object_2_h5_file(h5_filename, h5_tree_dict, specim_object):\n",
    "    with h5py.File(h5_filename, 'w', libver='latest') as f:\n",
    "        for attribute_name, h5_hierarchy_item_path in h5_tree_dict.items():\n",
    "            print(attribute_name)\n",
    "            dset = f.create_dataset(name=h5_hierarchy_item_path, \n",
    "                                            data = getattr(specim_object, attribute_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking the recording to user defined sizes and writing it to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n"
     ]
    }
   ],
   "source": [
    "# Define h5 file name\n",
    "H5_DIR = OUT_DIR + 'Input/H5/'\n",
    "\n",
    "# Every 1000 lines take up 0.85 GB at 8 Byte float. Therefore it could make sense to partition things that are larger than 2000 lines (sub GB for 32 float/4 byte)\n",
    "dtype = np.float32\n",
    "TRANSECT_CHUNK_SIZE_GB = 2\n",
    "TRANSECT_CHUNK_SIZE = 2000 # The number of lines (could also make a simple calculator for this)\n",
    "\n",
    "# It is nicer to deal with 4 byte numbers in general\n",
    "n_transects = df_start_stop.shape[0]\n",
    "for transect_number in range(n_transects):\n",
    "    start_line = df_start_stop['line_start'][transect_number]\n",
    "    stop_line = df_start_stop['line_stop'][transect_number]\n",
    "\n",
    "    n_chunks = int(np.ceil((stop_line-start_line)/TRANSECT_CHUNK_SIZE))\n",
    "\n",
    "    \n",
    "    for chunk_number in range(n_chunks):\n",
    "        chunk_start_idx = start_line + TRANSECT_CHUNK_SIZE*chunk_number\n",
    "\n",
    "        if chunk_number == n_chunks-1:\n",
    "            chunk_stop_idx = stop_line\n",
    "        else:\n",
    "            chunk_stop_idx = chunk_start_idx + TRANSECT_CHUNK_SIZE\n",
    "\n",
    "\n",
    "\n",
    "        data_cube = spectral_image_obj[chunk_start_idx:chunk_stop_idx, :, :]\n",
    "        # Calibration equation\n",
    "        specim_object.radiance_cube = ( (data_cube - dark_frame)*radiometric_frame/(metadata_obj.t_exp_ms/1000) ).astype(dtype = dtype) # 4 Byte\n",
    "        specim_object.hsi_timestamps = hsi_timestamps_total[chunk_start_idx:chunk_stop_idx]\n",
    "\n",
    "        # Possible to name files with <PREFIX>_<time_start>_<Transect#>_<Chunk#>.h5\n",
    "        h5_filename = H5_DIR + MISSION_NAME_PREFIX + '_transectnr_' + str(int(transect_number)) + '_chunknr_' + str(int(chunk_number)) + '.h5'\n",
    "\n",
    "        specim_object_2_h5_file(h5_filename=h5_filename, h5_tree_dict=h5_dict_write, specim_object=specim_object)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
